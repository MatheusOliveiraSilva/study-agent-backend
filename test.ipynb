{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.core.llm_config import LLMConfig\n",
    "from app.study_plan.agents.research_graph.tools import web_search\n",
    "\n",
    "config = LLMConfig(\n",
    "    provider=\"anthropic\", \n",
    "    model=\"claude-3-7-sonnet-latest\",\n",
    "    temperature=1,\n",
    "    max_tokens=2048,\n",
    "    thinking={\"type\": \"enabled\", \"budget_tokens\": 1024}\n",
    ")\n",
    "\n",
    "llm = config.get_llm()\n",
    "\n",
    "llm = llm.bind_tools([web_search])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=[] additional_kwargs={} response_metadata={'model_name': 'claude-3-7-sonnet-20250219'} id='run-0b8ef199-5cd5-4886-8dd1-0db2d20f2db7' usage_metadata={'input_tokens': 668, 'output_tokens': 4, 'total_tokens': 672, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}\n",
      "--------------------------------\n",
      "content=[{'thinking': 'The user is', 'type': 'thinking', 'index': 0}] additional_kwargs={} response_metadata={} id='run-0b8ef199-5cd5-4886-8dd1-0db2d20f2db7'\n",
      "--------------------------------\n",
      "The user is<thinking>\n",
      "content=[{'thinking': ' requesting a complete guide on AI engineering, and wants', 'type': 'thinking', 'index': 0}] additional_kwargs={} response_metadata={} id='run-0b8ef199-5cd5-4886-8dd1-0db2d20f2db7'\n",
      "--------------------------------\n",
      " requesting a complete guide on AI engineering, and wants<thinking>\n",
      "content=[{'thinking': ' me to search the web for information on this subject. The', 'type': 'thinking', 'index': 0}] additional_kwargs={} response_metadata={} id='run-0b8ef199-5cd5-4886-8dd1-0db2d20f2db7'\n",
      "--------------------------------\n",
      " me to search the web for information on this subject. The<thinking>\n",
      "content=[{'thinking': \" user's request is in Portuguese.\\n\\nI need to use\", 'type': 'thinking', 'index': 0}] additional_kwargs={} response_metadata={} id='run-0b8ef199-5cd5-4886-8dd1-0db2d20f2db7'\n",
      "--------------------------------\n",
      " user's request is in Portuguese.\n",
      "\n",
      "I need to use<thinking>\n",
      "content=[{'thinking': ' the web_search tool to gather information about AI engineering.', 'type': 'thinking', 'index': 0}] additional_kwargs={} response_metadata={} id='run-0b8ef199-5cd5-4886-8dd1-0db2d20f2db7'\n",
      "--------------------------------\n",
      " the web_search tool to gather information about AI engineering.<thinking>\n",
      "content=[{'thinking': ' The query should be in English since most web content is in English,', 'type': 'thinking', 'index': 0}] additional_kwargs={} response_metadata={} id='run-0b8ef199-5cd5-4886-8dd1-0db2d20f2db7'\n",
      "--------------------------------\n",
      " The query should be in English since most web content is in English,<thinking>\n",
      "content=[{'thinking': ' even though the request was made in Portuguese. Let me', 'type': 'thinking', 'index': 0}] additional_kwargs={} response_metadata={} id='run-0b8ef199-5cd5-4886-8dd1-0db2d20f2db7'\n",
      "--------------------------------\n",
      " even though the request was made in Portuguese. Let me<thinking>\n",
      "content=[{'thinking': ' search for information about AI engineering.', 'type': 'thinking', 'index': 0}] additional_kwargs={} response_metadata={} id='run-0b8ef199-5cd5-4886-8dd1-0db2d20f2db7'\n",
      "--------------------------------\n",
      " search for information about AI engineering.<thinking>\n",
      "content=[{'signature': 'ErUBCkYIAhgCIkADlTKzyGkzBXoGO1IPFkPapuBamBL2CDpcrxGf2cBoSEK/TnPsjgIo4DfgBxW4dHB5cYbMOBdcu+Bp23YAnq2KEgxA01SxxTqEYTUZnCIaDIvUHMR0KSy2/huK1yIw2Hob7ryXuOpV6qA9A1tE6Z+f4/EUzjK2PKJGxCLtTpbD4QAIaOeqkcHbecqcg7EIKh1VyVKPqBvifyS6ZStPStULUAevB6yKicP+KhXo7hgC', 'type': 'thinking', 'index': 0}] additional_kwargs={} response_metadata={} id='run-0b8ef199-5cd5-4886-8dd1-0db2d20f2db7'\n",
      "--------------------------------\n",
      "content=[{'text': 'Vou fazer uma pesquisa na web sobre AI Engineering (Engenharia de', 'type': 'text', 'index': 1}] additional_kwargs={} response_metadata={} id='run-0b8ef199-5cd5-4886-8dd1-0db2d20f2db7'\n",
      "--------------------------------\n",
      "Vou fazer uma pesquisa na web sobre AI Engineering (Engenharia de<text>\n",
      "content=[{'text': ' IA) para criar um guia completo', 'type': 'text', 'index': 1}] additional_kwargs={} response_metadata={} id='run-0b8ef199-5cd5-4886-8dd1-0db2d20f2db7'\n",
      "--------------------------------\n",
      " IA) para criar um guia completo<text>\n",
      "content=[{'text': ' para você.', 'type': 'text', 'index': 1}] additional_kwargs={} response_metadata={} id='run-0b8ef199-5cd5-4886-8dd1-0db2d20f2db7'\n",
      "--------------------------------\n",
      " para você.<text>\n",
      "content=[{'id': 'toolu_01GKceF12xWvr61Nz1ZDs1iE', 'input': {}, 'name': 'web_search', 'type': 'tool_use', 'index': 2}] additional_kwargs={} response_metadata={} id='run-0b8ef199-5cd5-4886-8dd1-0db2d20f2db7' tool_calls=[{'name': 'web_search', 'args': {}, 'id': 'toolu_01GKceF12xWvr61Nz1ZDs1iE', 'type': 'tool_call'}] tool_call_chunks=[{'name': 'web_search', 'args': '', 'id': 'toolu_01GKceF12xWvr61Nz1ZDs1iE', 'index': 2, 'type': 'tool_call_chunk'}]\n",
      "--------------------------------\n",
      "content=[{'partial_json': '', 'type': 'tool_use', 'index': 2}] additional_kwargs={} response_metadata={} id='run-0b8ef199-5cd5-4886-8dd1-0db2d20f2db7' tool_calls=[{'name': '', 'args': {}, 'id': None, 'type': 'tool_call'}] tool_call_chunks=[{'name': None, 'args': '', 'id': None, 'index': 2, 'type': 'tool_call_chunk'}]\n",
      "--------------------------------\n",
      "content=[{'partial_json': '{\"query\":', 'type': 'tool_use', 'index': 2}] additional_kwargs={} response_metadata={} id='run-0b8ef199-5cd5-4886-8dd1-0db2d20f2db7' tool_calls=[{'name': '', 'args': {}, 'id': None, 'type': 'tool_call'}] tool_call_chunks=[{'name': None, 'args': '{\"query\":', 'id': None, 'index': 2, 'type': 'tool_call_chunk'}]\n",
      "--------------------------------\n",
      "content=[{'partial_json': ' \"comp', 'type': 'tool_use', 'index': 2}] additional_kwargs={} response_metadata={} id='run-0b8ef199-5cd5-4886-8dd1-0db2d20f2db7' invalid_tool_calls=[{'name': None, 'args': ' \"comp', 'id': None, 'error': None, 'type': 'invalid_tool_call'}] tool_call_chunks=[{'name': None, 'args': ' \"comp', 'id': None, 'index': 2, 'type': 'tool_call_chunk'}]\n",
      "--------------------------------\n",
      "content=[{'partial_json': 'let', 'type': 'tool_use', 'index': 2}] additional_kwargs={} response_metadata={} id='run-0b8ef199-5cd5-4886-8dd1-0db2d20f2db7' invalid_tool_calls=[{'name': None, 'args': 'let', 'id': None, 'error': None, 'type': 'invalid_tool_call'}] tool_call_chunks=[{'name': None, 'args': 'let', 'id': None, 'index': 2, 'type': 'tool_call_chunk'}]\n",
      "--------------------------------\n",
      "content=[{'partial_json': 'e guide', 'type': 'tool_use', 'index': 2}] additional_kwargs={} response_metadata={} id='run-0b8ef199-5cd5-4886-8dd1-0db2d20f2db7' invalid_tool_calls=[{'name': None, 'args': 'e guide', 'id': None, 'error': None, 'type': 'invalid_tool_call'}] tool_call_chunks=[{'name': None, 'args': 'e guide', 'id': None, 'index': 2, 'type': 'tool_call_chunk'}]\n",
      "--------------------------------\n",
      "content=[{'partial_json': ' to AI en', 'type': 'tool_use', 'index': 2}] additional_kwargs={} response_metadata={} id='run-0b8ef199-5cd5-4886-8dd1-0db2d20f2db7' invalid_tool_calls=[{'name': None, 'args': ' to AI en', 'id': None, 'error': None, 'type': 'invalid_tool_call'}] tool_call_chunks=[{'name': None, 'args': ' to AI en', 'id': None, 'index': 2, 'type': 'tool_call_chunk'}]\n",
      "--------------------------------\n",
      "content=[{'partial_json': 'gineering c', 'type': 'tool_use', 'index': 2}] additional_kwargs={} response_metadata={} id='run-0b8ef199-5cd5-4886-8dd1-0db2d20f2db7' invalid_tool_calls=[{'name': None, 'args': 'gineering c', 'id': None, 'error': None, 'type': 'invalid_tool_call'}] tool_call_chunks=[{'name': None, 'args': 'gineering c', 'id': None, 'index': 2, 'type': 'tool_call_chunk'}]\n",
      "--------------------------------\n",
      "content=[{'partial_json': 'areer ski', 'type': 'tool_use', 'index': 2}] additional_kwargs={} response_metadata={} id='run-0b8ef199-5cd5-4886-8dd1-0db2d20f2db7' invalid_tool_calls=[{'name': None, 'args': 'areer ski', 'id': None, 'error': None, 'type': 'invalid_tool_call'}] tool_call_chunks=[{'name': None, 'args': 'areer ski', 'id': None, 'index': 2, 'type': 'tool_call_chunk'}]\n",
      "--------------------------------\n",
      "content=[{'partial_json': 'll', 'type': 'tool_use', 'index': 2}] additional_kwargs={} response_metadata={} id='run-0b8ef199-5cd5-4886-8dd1-0db2d20f2db7' invalid_tool_calls=[{'name': None, 'args': 'll', 'id': None, 'error': None, 'type': 'invalid_tool_call'}] tool_call_chunks=[{'name': None, 'args': 'll', 'id': None, 'index': 2, 'type': 'tool_call_chunk'}]\n",
      "--------------------------------\n",
      "content=[{'partial_json': 's re', 'type': 'tool_use', 'index': 2}] additional_kwargs={} response_metadata={} id='run-0b8ef199-5cd5-4886-8dd1-0db2d20f2db7' invalid_tool_calls=[{'name': None, 'args': 's re', 'id': None, 'error': None, 'type': 'invalid_tool_call'}] tool_call_chunks=[{'name': None, 'args': 's re', 'id': None, 'index': 2, 'type': 'tool_call_chunk'}]\n",
      "--------------------------------\n",
      "content=[{'partial_json': 'spons', 'type': 'tool_use', 'index': 2}] additional_kwargs={} response_metadata={} id='run-0b8ef199-5cd5-4886-8dd1-0db2d20f2db7' invalid_tool_calls=[{'name': None, 'args': 'spons', 'id': None, 'error': None, 'type': 'invalid_tool_call'}] tool_call_chunks=[{'name': None, 'args': 'spons', 'id': None, 'index': 2, 'type': 'tool_call_chunk'}]\n",
      "--------------------------------\n",
      "content=[{'partial_json': 'ibili', 'type': 'tool_use', 'index': 2}] additional_kwargs={} response_metadata={} id='run-0b8ef199-5cd5-4886-8dd1-0db2d20f2db7' invalid_tool_calls=[{'name': None, 'args': 'ibili', 'id': None, 'error': None, 'type': 'invalid_tool_call'}] tool_call_chunks=[{'name': None, 'args': 'ibili', 'id': None, 'index': 2, 'type': 'tool_call_chunk'}]\n",
      "--------------------------------\n",
      "content=[{'partial_json': 'ties\"}', 'type': 'tool_use', 'index': 2}] additional_kwargs={} response_metadata={} id='run-0b8ef199-5cd5-4886-8dd1-0db2d20f2db7' invalid_tool_calls=[{'name': None, 'args': 'ties\"}', 'id': None, 'error': None, 'type': 'invalid_tool_call'}] tool_call_chunks=[{'name': None, 'args': 'ties\"}', 'id': None, 'index': 2, 'type': 'tool_call_chunk'}]\n",
      "--------------------------------\n",
      "content='' additional_kwargs={} response_metadata={'stop_reason': 'tool_use', 'stop_sequence': None} id='run-0b8ef199-5cd5-4886-8dd1-0db2d20f2db7' usage_metadata={'input_tokens': 0, 'output_tokens': 183, 'total_tokens': 183, 'input_token_details': {}}\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "for chunk in llm.stream(\"Faça um guia completo de ai engineering, pesquise na web sobre o assunto\"):\n",
    "    print(chunk)\n",
    "    print(\"--------------------------------\")\n",
    "    if len(chunk.content) > 0 and chunk.content[0].get('thinking', None) is not None:\n",
    "        print(chunk.content[0]['thinking'], end=\"\", flush=True)\n",
    "        print(\"<thinking>\")\n",
    "    elif len(chunk.content) > 0 and chunk.content[0].get('text', None) is not None:\n",
    "        print(chunk.content[0]['text'], end=\"\", flush=True)\n",
    "        print(\"<text>\")\n",
    "    \n",
    "\n",
    "# content=[{'thinking': 'The user', 'type': 'thinking', 'index': 0}] additional_kwargs={} response_metadata={} id='run-d39a3dba-219b-4f32-8a7d-a09fb6e59d89'\n",
    "# content=[{'text': 'Para criar um guia completo sobre engenharia de IA (AI', 'type': 'text', 'index': 1}] additional_kwargs={} response_metadata={} id='run-d39a3dba-219b-4f32-8a7d-a09fb6e59d89'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No message found in input",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mapp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstudy_plan\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magents\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mresearch_graph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m research_graph\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m response = \u001b[43mresearch_graph\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtech_xp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m2 anos como desenvolvedor backend\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mactual_tech_stack\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPython, Langchain, LangGraph, SQL, Git\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcarrer_goals\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mQuero virar um AI Engineer, e internacionalizar minha carreira, ganhando em dolar\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mside_project_goal\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFazer um RAG chatbot com possibilidade de envio de documentos e imagens, monitorar tudo.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/study-agent-backend/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2739\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[39m\n\u001b[32m   2737\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2738\u001b[39m     chunks = []\n\u001b[32m-> \u001b[39m\u001b[32m2739\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2740\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2741\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2742\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2743\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2744\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2745\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2746\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2747\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2748\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2749\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2750\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2751\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/study-agent-backend/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2377\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2371\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2372\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   2373\u001b[39m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2374\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2375\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m   2376\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m2377\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2378\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2379\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2380\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2381\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2382\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2383\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2384\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2385\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/study-agent-backend/.venv/lib/python3.12/site-packages/langgraph/prebuilt/tool_node.py:235\u001b[39m, in \u001b[36mToolNode._func\u001b[39m\u001b[34m(self, input, config, store)\u001b[39m\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_func\u001b[39m(\n\u001b[32m    225\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    226\u001b[39m     \u001b[38;5;28minput\u001b[39m: Union[\n\u001b[32m   (...)\u001b[39m\u001b[32m    233\u001b[39m     store: Optional[BaseStore],\n\u001b[32m    234\u001b[39m ) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m     tool_calls, input_type = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m     config_list = get_config_list(config, \u001b[38;5;28mlen\u001b[39m(tool_calls))\n\u001b[32m    237\u001b[39m     input_types = [input_type] * \u001b[38;5;28mlen\u001b[39m(tool_calls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/study-agent-backend/.venv/lib/python3.12/site-packages/langgraph/prebuilt/tool_node.py:443\u001b[39m, in \u001b[36mToolNode._parse_input\u001b[39m\u001b[34m(self, input, store)\u001b[39m\n\u001b[32m    441\u001b[39m     message = messages[-\u001b[32m1\u001b[39m]\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo message found in input\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    445\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, AIMessage):\n\u001b[32m    446\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mLast message is not an AIMessage\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: No message found in input",
      "During task with name 'tools' and id '6265703b-ffda-5609-b985-154ad5e24f1c'"
     ]
    }
   ],
   "source": [
    "from app.study_plan.agents.research_graph.graph import research_graph\n",
    "\n",
    "response = research_graph.invoke(\n",
    "    {\n",
    "        \"tech_xp\": \"2 anos como desenvolvedor backend\", \n",
    "        \"actual_tech_stack\": \"Python, Langchain, LangGraph, SQL, Git\", \n",
    "        \"carrer_goals\": \"Quero virar um AI Engineer, e internacionalizar minha carreira, ganhando em dolar\", \n",
    "        \"side_project_goal\": \"Fazer um RAG chatbot com possibilidade de envio de documentos e imagens, monitorar tudo.\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
